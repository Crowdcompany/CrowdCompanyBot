# Crowdbot - Implementierungsplan

## Projektziel

Crowdbot ist ein selbst gehosteter KI-Assistent als sichere Alternative zu Moltbot mit folgenden Kernmerkmalen:

- Datensouveränität: Sensible Daten bleiben lokal
- Sicherheit: Kein Standard-Port, DM Pairing, Isolation, Allowlists
- Kosteneffizienz: GLM-4 via Proxy statt teurer Cloud-APIs
- Transparenz: Markdown-basiertes Gedächtnis

## Architektur

```
Telegram Bot (python-telegram-bot)
         ↓
Python Backend (Orchestrator, Memory Manager, Search Module)
         ↓
LLM Interface (GLM-4.7 via glmproxy.ccpn.cc)
```

## Tech-Stack

- Sprache: Python 3.11+ (mit virtueller Umgebung)
- LLM: GLM-4.7 via glmproxy.ccpn.cc (Anthropic Format)
- Messaging: Telegram Bot API (python-telegram-bot 21.11)
- Faktensuche: Perplexity Sonar via ppproxy.ccpn.cc
- Deep Research: Jina Deep Search via jinaproxy.ccpn.cc
- Web Scraping: Jina Reader (r.jina.ai)
- Gedächtnis: Markdown-Dateien (lokal)

## Implementierungsstatus

### Phase 1: Projekt-Setup
- [x] Ordnerstruktur: `/src`, `/data`, `/tests`
- [x] `.gitignore` für `.env`, `__pycache__`, `/data`
- [x] Virtuelle Python-Umgebung
- [x] `requirements.txt`

### Phase 2: Markdown-Gedächtnis V1
- [x] Pro User: `/data/users/{user_id}/memory.md`
- [x] `memory_manager.py` mit append_message() und get_context()
- [x] Format: Markdown-Header für User/Bot-Nachrichten

### Phase 8: Memory 2.0 - Hierarchisches Gedächtnis-System (GEPLANT)

**Ziel:** Intelligentes Memory-Management basierend auf Moltbot-Analyse

**Architektur:**
- [x] Strategie-Analyse von Moltbot abgeschlossen (30.01.2026)
- [x] Dateistruktur implementieren:
  - memory.md: Master Index mit Inhaltsverzeichnis
  - daily/: Tagesdateien (YYYYMMDD.md)
  - weekly/: Wochenzusammenfassungen (YYYY-WXX.md)
  - monthly/: Monatszusammenfassungen (YYYY-MM.md)
  - archive/: Komprimierte alte Dateien (.md.gz nach 90 Tagen)
  - important/: Persistente Präferenzen (preferences.md)

**Bereinigungslogik:**
- [ ] Cronjob für automatische Bereinigung (4 Uhr nachts)
- [ ] LLM-basierte Wichtigkeits-Bewertung:
  - Häufigkeit: Wie oft erwähnt (0-3 Punkte)
  - Recency: Wie kürzlich (0-2 Punkte)
  - Explizite Wichtigkeit: "Merke dir", "wichtig" (0-2 Punkte)
  - Persönliche Relevanz: Präferenzen, Abneigungen (0-3 Punkte)
  - Score 8-10: Persistent in memory.md
  - Score 5-7: Wochen-/Monatszusammenfassungen
  - Score 2-4: Nach 7 Tagen archivieren
  - Score 0-1: Nach 24h entfernen (TV-Programm, Wetter)

**Progressive Verdichtung (inspiriert von Moltbot):**
- [ ] T+1 Tag: Soft Trim (Details entfernen, Zusammenfassungen behalten)
- [ ] T+7 Tage: Weekly Summary via LLM, Original → Archive
- [ ] T+30 Tage: Monthly Summary, Wochen → Archive
- [ ] T+365 Tage: Yearly Summary, nur Essentials in memory.md
- [ ] T+90 Tage: Archiv-Kompression (.md.gz)

**Dual-Trigger-System:**
- [ ] Zeit-basiert: Nach X Tagen bereinigen
- [ ] Größen-basiert: Bei > 5MB Dateigröße triggen

**Schutzmaßnahmen:**
- [ ] Letzte 7 Tage nie automatisch bereinigen
- [ ] important/preferences.md nie bereinigen
- [ ] Benutzer-Fragen immer behalten
- [ ] Projektentscheidungen markieren und schützen

**Kontextladen-Strategie:**
- [ ] Standard: memory.md + letzte 3 Tagesdateien + preferences.md
- [ ] LLM-Analyse: Identifiziere relevante historische Dateien
- [ ] Token-Limit: Max 50% Context Window für Memory
- [ ] Bei Überschreitung: Älteste Dateien überspringen

**Implementierung:**
- [x] file_structure.py für Ordnerstruktur-Verwaltung (340 Zeilen)
- [x] memory_manager_v2.py mit V2 Funktionen (550 Zeilen)
- [x] importance_scorer.py für LLM-basierte Bewertung (420 Zeilen)
- [x] summarizer.py für progressive Verdichtung (380 Zeilen)
- [x] cleanup_service.py für Cronjob-Logik (450 Zeilen)
- [x] context_loader.py für intelligentes Kontextladen (320 Zeilen)
- [x] Tests geschrieben (12 Tests in test_memory_v2.py)

**Dokumentation:**
- [x] Context/MemoryStrategy.md mit vollständiger Architektur
- [ ] README.md aktualisieren
- [ ] CHANGELOG.md: Version 2.0 Entry

### Phase 3: LLM Client
- [x] GLM-4.7 via glmproxy.ccpn.cc (Anthropic Format)
- [x] System-Prompt für Crowdbot mit TTS-Anweisungen
- [x] Tool-System implementiert (Tool-Registrierung)
- [x] Intention-basierte Tool-Nutzung
- [x] Test-Call erfolgreich

### Phase 4: Telegram Integration
- [x] `bot.py` mit Handler-Struktur
- [x] /start, /reset, /help Handler
- [x] /search Handler (Perplexity für Fakten)
- [x] /searchmd Handler (mit Markdown-Datei Download)
- [x] /deepresearch Handler (Jina für Analysen)
- [x] Text-Handler mit Memory-Integration
- [x] Typing-Indikator während Verarbeitung

### Phase 5: Testing
- [x] Unit-Tests für Memory Manager (6 Tests)
- [x] Unit-Tests für LLM Client (5 Tests)
- [x] Unit-Tests für Search Module (9 Tests)
- [x] Integrationstests (4 Tests)
- [x] Authentifizierungstests (8 Tests)
- [x] Alle 32 Tests bestanden

### Phase 6: Internet-Suche (ERWEITERT)
- [x] `search_module.py` mit drei Such-Modi:
  - Perplexity Sonar für schnelle Fakten
  - Jina Deep Research für Analysen
  - Jina Reader für einzelne URLs
- [x] Intelligente Auswahl basierend auf Keywords
- [x] TTS-kompatible Formatierung (_make_tts_compatible)
- [x] Markdown-Format für Downloads
- [x] Tool-Integration im LLM Client

## Funktionsumfang

- **/start**: Erstellt User-Ordner mit memory.md, begrüßt User
- **/reset**: Setzt Gedächtnis zurück, erstellt neue memory.md
- **/help**: Zeigt Hilfe zu allen Befehlen und Funktionen
- **/search <Anfrage>**: Schnelle Faktensuche mit Perplexity (TTS-optimiert)
- **/searchmd <Anfrage>**: Suche mit vollständigem Markdown als Download
- **/deepresearch <Anfrage>**: Ausführliche Analyse mit Jina Deep Research
- **Textnachrichten**: Chat mit LLM, automatische Tool-Nutzung, Gedächtnis-Integration
- **Kontext**: Lädt letzte 10 Nachrichten aus memory.md für Konversationskontext

## API-Konfiguration

### GLM-4.7 Proxy
- URL: https://glmproxy.ccpn.cc/v1/messages
- Format: Anthropic API
- Modell: glm-4.7
- Kein API-Key erforderlich

### Perplexity Proxy (Faktensuche)
- URL: https://ppproxy.ccpn.cc/chat/completions
- Format: OpenAI-kompatibel
- Modell: sonar
- Verwendung: Nachrichten, TV-Programme, schnelle Fakten
- Kein API-Key erforderlich

### Jina Deep Search
- URL: https://jinaproxy.ccpn.cc/v1/chat/completions
- Format: OpenAI-kompatibel
- Modell: jina-deepsearch-v1
- Verwendung: Ausführliche Analysen, Wikipedia-ähnlich
- Kein API-Key erforderlich

### Jina Reader
- URL: https://r.jina.ai/
- Verwendung: Einzelne URLs scrapen
- Kein API-Key erforderlich

### Telegram
- Bot-Token vom @BotFather erforderlich
- User Chat-IDs von @userinfobot oder @get_id_bot
- In .env speichern als TELEGRAM_BOT_TOKEN und ALLOWED_USER_IDS

## Sicherheitsanforderungen

1. Kein Standard-Port
2. Isolation in VM oder Docker
3. Input Sanitization gegen Markdown-Injections
4. Token-Sicherheit: .env niemals committen

## Antwortformate

### Chat-Antworten
- Alle Chat-Antworten müssen TTS-kompatibel sein (Text-to-Speech)
- Kein Markdown im Chat (keine Sternchen, Unterstriche, Backticks, etc.)
- Fließender Text in ganzen Sätzen
- Keine Sonderzeichen die von TTS vorgelesen werden (wie *, _, =, etc.)

### Markdown-Antworten
- Markdown nur als herunterladbare Datei
- Vollständiges Formatierung erhältlich
- Nur über expliziten Befehl (/searchmd)

## Dateistruktur

```
Crowdbot/
├── .env                    # API Keys (NICHT im Git)
├── .env.example            # Beispiel-Konfiguration
├── .gitignore              # Sensible Dateien ausschließen
├── .plan                   # Dieser Plan
├── requirements.txt        # Python-Abhängigkeiten
├── README.md              # Dokumentation
├── venv/                  # Virtuelle Umgebung
├── src/
│   ├── __init__.py
│   ├── bot.py             # Telegram Bot Main
│   ├── memory_manager.py  # Gedächtnis-Verwaltung
│   ├── llm_client.py      # GLM-4 API Client
│   └── search_module.py   # Jina Suche
├── data/
│   └── users/
│       └── {user_id}/
│           └── memory.md  # Konversationsverlauf
└── tests/
    ├── test_memory.py     # Unit-Tests (6 Tests)
    ├── test_llm_client.py # Unit-Tests (5 Tests)
    ├── test_search.py     # Unit-Tests (9 Tests)
    └── test_integration.py # Integrationstests (3 Tests)
```

## Phase 7: Sicherheits-Härtung ✓ ABGESCHLOSSEN

Nach dem Sicherheitsaudit wurden kritische Sicherheitsfeatures implementiert:

### 7.1 Telegram-Authentifizierung ✓ ABGESCHLOSSEN
- [x] User-Allowlist implementiert in `src/bot.py`
- [x] ALLOWED_USER_IDS aus .env geladen
- [x] Komma-separierte Liste von Chat-IDs
- [x] Prüfung bei allen Handler-Funktionen (6 Handler)
- [x] `is_authorized()` und `check_authorization()` Funktionen
- [x] Freundliche Ablehnung für nicht-autorisierte User
- [x] Logging von unauthorisierten Zugriffsversuchen
- [x] Tests geschrieben (8 Tests, alle bestanden)

### 7.2 Input-Validierung ✓ IMPLEMENTIERT
- [x] Telegram-Limit (4096 Zeichen) wird respektiert
- [x] Sichere Dateinamen-Generierung in `search_md_command()`
- [x] Alphanumerische Validierung für Query-basierte Dateinamen
- [x] Längen-Limitierung für Dateinamen (50 Zeichen)
- [x] TTS-kompatible Formatierung entfernt problematische Zeichen

### 7.3 Token-Sicherheit ✓ IMPLEMENTIERT
- [x] .env in .gitignore
- [x] Keine API-Keys im Code
- [x] Alle Secrets über Umgebungsvariablen
- [x] .env.example als Vorlage erstellt

### 7.4 TTS-Kompatibilität ✓ IMPLEMENTIERT
- [x] `_remove_markdown()` Funktion im Bot
- [x] `_make_tts_compatible()` Funktion im Search Module
- [x] Alle Bot-Antworten werden gefiltert
- [x] Sonderzeichen-Ersetzung (=, +, |, etc.)
- [x] Fließtext-Formatierung

### Noch offen (optionale Erweiterungen):

#### 7.5 Relative Pfade (Optional)
- [ ] Hardcodierte Pfade durch DATA_DIR aus .env ersetzen
- [ ] Standard: `./data` relativ zum Projektverzeichnis

#### 7.6 Rate Limiting (Optional)
- [ ] Rate Limiter Klasse implementieren
- [ ] 10 Anfragen pro Minute pro User
- [ ] RATE_LIMIT_PER_MINUTE in .env
- [ ] Cooldown für Deep Search

### Priorität 2 - Dependencies Update:

- [ ] `requirements.txt` aktualisieren:
  - requests auf >= 2.32.0
  - aiohttp auf >= 3.10.0
- [ ] `pip audit` ausführen

### Priorität 3 - Geplant für später:

- Logging-Sicherheit: Sensible Daten maskieren
- Security-Tests: Automated Input-Validierung
- Error Handling: Nur für authentifizierte User

### Technische Details:

**Umgebungsvariablen in .env:**
```
TELEGRAM_BOT_TOKEN=...
ALLOWED_USER_IDS=YOUR_CHAT_ID
RATE_LIMIT_PER_MINUTE=10
DATA_DIR=./data
```

**Authentifizierungs-Logik:**
```python
def is_authorized(user_id: int) -> bool:
    allowed_ids = os.getenv("ALLOWED_USER_IDS", "").split(",")
    return str(user_id) in allowed_ids
```

**Rate Limiter:**
```python
class RateLimiter:
    def __init__(self, max_requests: int, time_window: int = 60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = {}  # {user_id: [timestamps]}
```

## Phase 9: Task Manager System ✓ VOLLSTÄNDIG IMPLEMENTIERT (31. Januar 2026)

**Ziel:** Ermöglicht dem Bot, Python-Skripte für Benutzer zu erstellen, zu verwalten und auszuführen.

**Architektur:**
- [x] Task-Verwaltung: Erstellung, Update, Status-Tracking
- [x] Script-Versionierung: Jede Änderung erhöht die Version
- [x] Execution History: Speichert Outputs, Errors und Ausführungszeiten
- [x] Skill-System: Wiederverwendbare Scripts speichern und laden
- [x] Dateistruktur: important/tasks/{active,completed,archived,workspace}
- [x] Dateistruktur: important/skills/ für wiederverwendbare Scripts

**Implementierung:**
- [x] task_manager.py (720 Zeilen)
  - create_task(): Task erstellen mit LLM-generiertem Snake-Case Namen
  - get_task(): Task laden
  - update_task(): Status, Script, Execution History aktualisieren
  - list_tasks(): Tasks nach Status filtern (default: "all")
  - delete_task(): Task archivieren
  - **run_task()**: ✓ IMPLEMENTIERT (31.01.2026 11:52 Uhr)
    - Automatische Script-Generierung via LLM wenn Script leer
    - Sichere Ausführung mit subprocess (30s Timeout)
    - User-Input als sys.argv[1] Parameter
    - Markdown-Code-Block-Bereinigung
    - Execution History wird gespeichert
  - save_as_skill(): Task als Skill speichern
  - get_skill(): Skill laden
  - list_skills(): Alle Skills auflisten
- [x] file_structure.py erweitert:
  - Tasks-Ordner: active/, completed/, archived/, workspace/
  - Skills-Ordner: skills/
  - Index-Dateien: tasks/index.md, skills/index.md
- [x] Tests geschrieben: test_task_manager.py (17 Tests, alle bestehen)
- [x] Integration mit FileStructureManager

**Bot-Integration:** ✓ VOLLSTÄNDIG ABGESCHLOSSEN (31.01.2026 12:00 Uhr)
- [x] /task create <Beschreibung> - Task erstellen
- [x] /task list - Alle Tasks anzeigen (active, completed, archived)
- [x] /task show <task_id> - Task-Details anzeigen
- [x] /task run <task_id> [parameter] - Task ausführen
- [x] /task delete <task_id> - Task löschen
- [x] /skill Command implementiert (save, list, show, run, delete)
- [x] Bot-Commands bei Telegram registriert
- [x] /help zeigt alle Task-Commands
- [x] Fehler behoben: LLM-Client Aufruf korrigiert (user_message statt messages)
- [x] Fehler behoben: run_task() Methode implementiert
- [x] API-Dokumentation: Context/TaskManagerAPI.md

**Task-Namen-Format (AKTUELL 31.01.2026):**
- Task-Namen: ENGLISCH, Snake-Case (z.B. "add_7_numbers", "is_prime")
- Task-IDs: Identisch mit Task-Namen
- Few-Shot LLM-Prompt mit englischen Beispielen
- Automatische Konfliktbehandlung (_v2, _v3 bei Duplikaten)
- Fallback bei LLM-Fehler: Erste 4 Wörter der Beschreibung

**Test-Ergebnisse:**
- 17 Task Manager Tests - alle bestehen ✓
- Task-Erstellung, -Update, -Löschung funktionieren
- Task-Ausführung mit LLM-Script-Generierung funktioniert
- Skill-System funktioniert
- Status-Wechsel (active → completed → archived) funktionieren

## Nächste Schritte (Phase 10+)

### KRITISCH (sofort implementieren):
- Phase 10: Automatische Task-Ausführung im Chat ⚠️ NEU (31.01.2026)
  - [ ] Tool-Funktion `execute_task(user_query)` für LLM implementieren
  - [ ] Semantische Task-Suche basierend auf Beschreibung
  - [ ] LLM entscheidet automatisch: Neue Task erstellen vs. Existierende ausführen
  - [ ] Automatische Parameter-Extraktion aus User-Query
  - [ ] Integration in normalen Chat-Workflow (nicht nur /task Commands)
  - **Ziel:** User sagt "Berechne Fibonacci" → Bot findet Task oder erstellt neue → Führt aus
  - **Implementierungsdetails:**
    - Tool registrieren: `_tool_execute_task(query: str) -> str`
    - list_tasks() durchsuchen nach ähnlicher Beschreibung
    - Bei Match: run_task() aufrufen mit extrahierten Parametern
    - Bei Kein Match: create_task() + run_task() in einem Schritt
    - Antwort: TTS-kompatibles Ergebnis

### EMPFOHLEN (mittelfristig):
- Phase 11: Dependencies aktualisieren
  - [ ] requirements.txt auf neueste Versionen (requests 2.32.3, aiohttp 3.11.11, python-telegram-bot 21.11)
  - [ ] pip audit ausführen
  - [ ] Lokal testen
  - [ ] Neu deployen auf Coolify
- Phase 12: Datei-Permissions korrigieren
  - [ ] .env Datei: chmod 600 (nur Owner kann lesen/schreiben)

- Phase 13: Prompt Injection Defense (LLM Input Validation)
  - [ ] Prompt-Validierung VOR LLM-Übergabe implementieren
  - [ ] Technologien evaluieren:
    - Option 1: NeMo Guardrails (NVIDIA)
    - Option 2: Guardrails AI (Open Source)
    - Option 3: LangChain Input Guards
    - Option 4: Custom Regex-basierte Filterung
  - [ ] System-Prompt-Override-Detection
  - [ ] Jailbreak-Pattern-Detection
  - [ ] Content-Policy-Validation
  - [ ] Tests für bekannte Prompt-Injection-Techniken
  - Dokumentation: Context/PromptInjectionDefense.md

- Phase 14: Rate Limiting implementieren
  - [ ] Rate Limiter Klasse (10-20 Nachrichten/Minute pro User)
  - [ ] RATE_LIMIT_PER_MINUTE in .env
  - [ ] DoS-Schutz durch autorisierte User
  - [ ] Cooldown für Deep Search

- Phase 15: Monitoring verbessern
  - [ ] Health-Endpoint mit Status-Infos (optional HTTP-Server)
  - [ ] Alerting bei Fehlern
  - [ ] Log-Rotation für lange Laufzeiten

### OPTIONAL (Nice-to-have):
- Phase 16: Verschlüsselung der Memory-Dateien at-rest
- Phase 17: Backup-Strategie für /data Volume
- Phase 18: Erweiterte Telegram-Features (Dateien, Bilder, Sprachnachrichten)
- Phase 19: Dashboard und Monitoring-UI
- Phase 20: Multi-Bot-Support

## Status (Stand: 30. Januar 2026)

✓ **PRODUKTIV EINSETZBAR (Version 1.0)**

Der Crowdbot ist voll funktionsfähig mit:
- ✓ GLM-4.7 Sprachmodell (via glmproxy.ccpn.cc)
- ✓ Perplexity Sonar für schnelle Faktensuche
- ✓ Jina Deep Research für ausführliche Analysen
- ✓ Markdown-basiertes Gedächtnis V1 (lokal, einfache Dateistruktur)
- ✓ Telegram User-Authentifizierung (Allowlist)
- ✓ TTS-kompatible Ausgaben
- ✓ Tool-System mit automatischer Nutzung
- ✓ Alle 32 Tests bestanden

**Letzte Implementierung:** Phase 7 - Sicherheits-Härtung (abgeschlossen)

**Aktueller Stand:** Phase 8 - Memory 2.0 VOLLSTÄNDIG AKTIVIERT (30.01.2026 19:35 Uhr)

**Dokumentation aktualisiert:** 30. Januar 2026
- README.md zeigt aktuellen Stand und verfügbare Features
- CHANGELOG.md dokumentiert Version 1.0 Release und Memory 2.0 Aktivierung
- CLAUDE.md enthält vollständige Entwickler-Anweisungen
- Context/MemoryStrategy.md beschreibt Memory 2.0 Architektur

Implementierte und AKTIVIERTE Memory 2.0 Komponenten:
- ✓ FileStructureManager: Hierarchische Ordnerstruktur, Archivierung, Kompression
- ✓ MemoryManagerV2: Rückwärtskompatibel, Tagesdateien, V1→V2 Migration
- ✓ ImportanceScorer: LLM-basierte Bewertung (0-10 Punkte), Fallback-Heuristiken
- ✓ Summarizer: Soft Trim, Weekly/Monthly/Yearly Summaries
- ✓ CleanupService: Automatische Bereinigung, Dual-Trigger, Emergency Cleanup
- ✓ ContextLoader: Intelligentes Laden, LLM-basierte Dateiauswahl
- ✓ Tests: 12 umfassende Tests für alle Komponenten
- ✓ migrate_v1_to_v2.py: Migrations-Skript erstellt und getestet

Aktivierungsschritte abgeschlossen (30.01.2026):
- ✓ bot.py auf MemoryManagerV2 umgestellt
- ✓ Migration von V1 zu V2 für User 7043093505 durchgeführt
- ✓ Hierarchische Ordnerstruktur angelegt
- ✓ memory.md Index und preferences.md erstellt
- ✓ 38 Konversationen erfolgreich migriert

Optional für später:
- Cronjob-Setup für automatischen Cleanup (manuell via cleanup_service.py möglich)

Der Bot läuft jetzt mit Memory 2.0!
